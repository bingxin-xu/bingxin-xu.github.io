<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Bingxin Xu</title>
<link rel="stylesheet" href="styles.css">
</head>
<body>
<header>
    <h1>Bingxin Xu</h1>
    <nav>
        <ul>
            <li><a href="#bio">Bio</a></li>
            <li><a href="#publications">Publications</a></li>
            <li><a href="#contact">Contact</a></li>
        </ul>
    </nav>
</header>

<section id="bio">
    <h2>Bio</h2>
    <div class="bio-content">
        <img src="assets/BingxinXu_LinkedIn.jpg" alt="My Photo" class="bio-photo">
        <p>Hi everyone! I'm Bingxin Xu, first-year <b>Ph.D.</b> student in Computer Science at <b>University of Southern California</b>, advised by Prof. <a href="https://viterbi.usc.edu/directory/faculty/Ferrara/Emilio">Emilio Ferrara</a>. </p>
        <p>My research focuses on Efficient and Trustworthy AI, especially for large language model (LLM), multi-modal large language models (MLLM) and vision-language-action models (VLA). </p>
        <p>Before joining USC, I worked as research assistant under the mentorship of Prof. <a href="https://tomyan555.github.io/">Yan Yan</a> from Illinois Institute of Technology. Previously, I received my M.S. in Data Science and B.S. in Computer Science from Illinois Institute of Technology.</p>
    </div>
</section>



<section id="publications">
    <h2>Selected publications</h2>
    <p>Google Scholar: <a href="https://scholar.google.com/citations?user=ohV-Kd4AAAAJ&hl=en">Bingxin Xu</a></p>
    <div class="publication">
    <img src="assets/PruMerge.png" alt="PruMerge 2024">
    <div class="publication-info">
        <h4>LLaVA-PruMerge: Adaptive Token Reduction for Efficient Large Multimodal Models</h4>
        <p><u>Bingxin Xu*</u>,Yuzhang Shang*, Mu Cai*, Yong Jae Lee, Yan Yan</p>
        <p>International Conference on Computer Vision (ICCV), 2025</p>
        <div class="buttons">
            <a href="https://openaccess.thecvf.com/content/ICCV2025/papers/Shang_LLaVA-PruMerge_Adaptive_Token_Reduction_for_Efficient_Large_Multimodal_Models_ICCV_2025_paper.pdf" class="apple-style-button">Paper</a>
            <a href="https://github.com/42Shawn/LLaVA-PruMerge" class="apple-style-button">Code</a>
        </div>
    </div>
    </div>
    
    <div class="publication">
        <img src="assets/freePruner.png" alt="freePruner 2024">
        <div class="publication-info">
            <h4>freePruner: A Training-free Approach for Large Multimodal Model Acceleration</h4>
            <p><u>Bingxin Xu</u>, Yuzhang Shang, Yunhao Ge, Qian Lou, Yan Yan</p>
            <p>arXiv Nov.2024</p>
            <a href="https://arxiv.org/abs/2411.15446" class="apple-style-button">Paper</a>
        </div>
    </div>

    <div class="publication">
        <img src="assets/ButterflyQuant.png" alt="ButterflyQuant 2025">
        <div class="publication-info">
            <h4>ButterflyQuant: Ultra-low-bit LLM Quantization through Learnable Orthogonal Butterfly Transforms</h4>
            <p><u>Bingxin Xu</u>, Zhen Dong, Oussama Elachqar, Yuzhang Shang</p>
            <p>arXiv Sep.2025</p>
            <a href="https://arxiv.org/abs/2509.09679" class="apple-style-button">Paper</a>
        </div>
    </div>
    
    <div class="publication">
        <img src="assets/VideoLLM.png" alt="VideoLLM 2024">
        <div class="publication-info">
            <h4>Interpolating Video-LLMs: Toward Longer-sequence LMMs in a Training-free Manner</h4>
            <p><u>Bingxin Xu*</u>, Yuzhang Shang*, Weitai Kang, Mu Cai, Yuheng Li, Zehao Wen, Zhen Dong, Kurt Keutzer, Yong Jae Lee, Yan Yan</p>
            <p>arXiv Sep.2024</p>
            <a href="https://arxiv.org/abs/2409.12963" class="apple-style-button">Paper</a>
        </div>
    </div>

    <div class="publication">
        <img src="assets/ECAR.png" alt="ECAR 2024">
        <div class="publication-info">
            <h4>E-CAR: Efficient Continuous Autoregressive Image Generation via Multistage Modeling</h4>
            <p>Zhihang Yuan, Yuzhang Shang, Hanling Zhang, Tongcheng Fang, Rui Xie, <u>Bingxin Xu</u>, Yan Yan, Shengen Yan, Guohao Dai, Yu Wang</p>
            <p>arXiv Dec.2024</p>
            <a href="https://arxiv.org/abs/2412.14170" class="apple-style-button">Paper</a>
        </div>
    </div>

    <div class="publication">
        <img src="assets/ICCV2023.png" alt="ICCV 2023">
        <div class="publication-info">
            <h4>Causality Guided Data-free Network Quantization</h4>
            <p>Yuzhang Shang, <u>Bingxin Xu</u>, Gaowen Liu, Ramana Rao Kompella, Yan Yan</p>
            <p>International Conference on Computer Vision (ICCV), 2023</p>
            <div class="buttons">
                <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Shang_Causal-DFQ_Causality_Guided_Data-Free_Network_Quantization_ICCV_2023_paper.pdf" class="apple-style-button">Paper</a>
                <a href="https://github.com/42Shawn/Causal-DFQ" class="apple-style-button">Code</a>
            </div>
        </div>
    </div>


</section>

<section id="contact">
    <h2>Contact</h2>
    <!-- <p>Ways to get in touch with me:</p> -->
    <p>Email: <a href="mailto:bingxin.xu.ai@gmail.com">bingxin.xu.ai@gmail.com</a></p>
</section>


</body>
</html>
